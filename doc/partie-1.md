# Partie 1 â€“ Exploration et cycle de vie des donnÃ©es

---

## 1 - Fiche descriptive des donnÃ©es - DÃ©tection de fraude

### Vue d'ensemble rapide
- **Dataset** : Credit Card Fraud Detection (Kaggle/ULB)  
- **Volume** : 284 807 transactions sur 2 jours  
- **DÃ©fi principal** : DÃ©sÃ©quilibre extrÃªme (0.17% de fraudes)

### CaractÃ©ristiques clÃ©s
- **39 variables** (31 originales + 8 enrichies) :  
  - 28 anonymisÃ©es (PCA)  
  - `Time` (temps en secondes depuis 1Ã¨re transaction)  
  - `Amount` (montant en â‚¬)  
  - `Class` (0=Normal, 1=Fraude)  
  - **8 nouvelles variables crÃ©Ã©es** :
    - Temporelles : `Hour`, `Day`, `Is_Night`, `Is_Weekend`
    - Montants : `Amount_log`, `Amount_Category`
    - PCA : `PCA_Magnitude`, `PCA_Extreme_Count`
- **492 fraudes** vs **284 315 normales** â†’ Ratio â‰ˆ **1:578**  
- DonnÃ©es collectÃ©es en **Europe (septembre 2013)**, anonymisÃ©es pour confidentialitÃ©  
- **QualitÃ©** : 0 valeurs manquantes âœ…

---

### DÃ©sÃ©quilibre des classes
- **Normales** : 99.83%  
- **Fraudes** : 0.17%  
- **Impact** : les modÃ¨les tendent Ã  prÃ©dire "normal" par dÃ©faut  
- **Solution** : techniques de rÃ©Ã©quilibrage (SMOTE, sous-Ã©chantillonnage)

---

### Analyses exploratoires

#### Montants
- Transactions normales â†’ Moyenne â‰ˆ **88â‚¬**, mÃ©diane â‰ˆ **23â‚¬**  
- Transactions frauduleuses â†’ Moyenne â‰ˆ **122â‚¬**, mÃ©diane â‰ˆ **9â‚¬**  
- **Insight** : Les fraudes concernent souvent de **petits montants (0-50â‚¬)** mais quelques cas isolÃ©s Ã  trÃ¨s gros montants augmentent la moyenne.

#### TemporalitÃ©
- DurÃ©e couverte : ~**2 jours**  
- Transactions normales â†’ pic dâ€™activitÃ© en journÃ©e (**8h-20h**)  
- Fraudes â†’ prÃ©sentes jour et nuit, mais en nombre plus faible la nuit  
- **Insight** : lâ€™heure de la transaction (`Hour`) est une feature potentiellement utile.

#### Features PCA
- Les 5 plus corrÃ©lÃ©es avec la cible `Class` : **V14, V17, V12, V10, V16**  
- Distribution trÃ¨s diffÃ©rente entre fraudes et normales â†’ **fort pouvoir discriminant**

---

### MÃ©triques de performance Ã  retenir
- âŒ **Accuracy** â†’ trompeuse (modÃ¨le biaisÃ© vers classe majoritaire)  
- âœ… **Recall** â†’ dÃ©tecter un maximum de fraudes (prioritÃ© mÃ©tier)  
- âœ… **Precision** â†’ limiter les faux positifs  
- âœ… **F1-Score** â†’ Ã©quilibre Recall / Precision  
- âœ… **AUC-ROC** â†’ Ã©valuer la sÃ©paration globale  

---

## 2 - Cycle de vie des donnÃ©es - DÃ©tection de fraude

### Pipeline MLOps simplifiÃ©
```
ğŸ“¥ Ingestion â†’ ğŸ—ƒï¸ Stockage â†’ âš™ï¸ Preprocessing â†’ ğŸ¤– ModÃ©lisation â†’ ğŸš€ DÃ©ploiement â†’ ğŸ“Š Monitoring
```

---

### 1. Ingestion des donnÃ©es
- **Temps rÃ©el** : Kafka (flux de transactions live)  
- **Batch** : CSV historiques via Airflow  
- **Externes** : listes noires, gÃ©olocalisation  

---

### 2. Stockage data lake (3 couches)
- **Bronze** â†’ donnÃ©es brutes (S3/Parquet)  
- **Silver** â†’ donnÃ©es nettoyÃ©es (Delta Lake)  
- **Gold** â†’ donnÃ©es prÃªtes pour ML (PostgreSQL)  

---

### 3. Preprocessing automatisÃ©
1. Validation des schÃ©mas et cohÃ©rence  
2. Nettoyage doublons, valeurs manquantes  
3. Feature engineering (8 nouvelles variables) :
   - Temporelles : `Hour`, `Day`, `Is_Night`, `Is_Weekend`
   - Montants : `Amount_log`, `Amount_Category`
   - PCA : `PCA_Magnitude`, `PCA_Extreme_Count`
4. RÃ©Ã©quilibrage â†’ SMOTE / donnÃ©es synthÃ©tiques  

---

### 4. Pipeline Airflow automatisÃ©
**DAG quotidien (2h00 UTC)** :  
```
Ingestion â†’ Preprocessing â†’ SynthÃ©tique â†’ EntraÃ®nement â†’ Validation â†’ DÃ©ploiement
```
- Retry automatique  
- Alertes en cas dâ€™Ã©chec  
- Monitoring en continu  

---

### 5. DÃ©ploiement et production
- **Architecture** : Kubernetes + FastAPI + autoscaling  
- **API prÃ©diction** : `/api/predict` (latence <100ms)  
- **CI/CD** : tests â†’ build â†’ staging â†’ production  

---

### 6. Monitoring temps rÃ©el
- **KPIs mÃ©tier** :  
  - Taux de dÃ©tection fraude > 85%  
  - Faux positifs < 5%  
  - Latence API < 100ms  
- **Outils** : Grafana dashboards + Alertes Slack/PagerDuty  

---

### 7. AmÃ©lioration continue
- RÃ©entraÃ®nement dÃ©clenchÃ© si :  
  - Baisse de performance (AUC < seuil)  
  - Data drift dÃ©tectÃ©  
  - Feedback mÃ©tier (enquÃªtes manuelles)  
