"""
Pipeline Airflow pour la DÃ©tection de Fraude Bancaire
======================================================

Ce DAG automatise l'ensemble du processus de traitement des donnÃ©es,
gÃ©nÃ©ration de donnÃ©es synthÃ©tiques et prÃ©paration pour l'entraÃ®nement des modÃ¨les
de dÃ©tection de fraude bancaire.

Auteur: Ã‰quipe Data Science - NÃ©obanque Fluzz
Version: 1.0
Date: AoÃ»t 2025
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.task_group import TaskGroup
import sys
import os
from pathlib import Path

# Ajouter le chemin du projet pour importer nos modules
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

# Imports de nos modules personnalisÃ©s
from config.config import (
    DATA_CONFIG, 
    PREPROCESSING_CONFIG, 
    SYNTHETIC_DATA_CONFIG,
    AIRFLOW_CONFIG,
    get_config_section,
    validate_config
)
from src.utils import (
    setup_logging,
    validate_dataset_quality,
    calculate_class_balance_metrics,
    save_model_artifacts,
    generate_pipeline_report
)

# Configuration par dÃ©faut des tÃ¢ches Airflow (utilise config.py)
default_args = {
    'owner': 'data-science-team',
    'start_date': datetime.strptime(AIRFLOW_CONFIG['dag']['start_date'], '%Y-%m-%d'),
    'retries': AIRFLOW_CONFIG['tasks']['default_retries'],
    'retry_delay': timedelta(minutes=int(AIRFLOW_CONFIG['tasks']['retry_delay'].replace('m', ''))),
    'email_on_failure': AIRFLOW_CONFIG['tasks']['email_on_failure'],
    'email_on_retry': AIRFLOW_CONFIG['tasks']['email_on_retry'],
}

# DÃ©finition du DAG principal (utilise config.py)
dag = DAG(
    AIRFLOW_CONFIG['dag']['dag_id'],
    default_args=default_args,
    description=AIRFLOW_CONFIG['dag']['description'],
    schedule=AIRFLOW_CONFIG['dag']['schedule_interval'],
    start_date=datetime.strptime(AIRFLOW_CONFIG['dag']['start_date'], '%Y-%m-%d'),
    catchup=AIRFLOW_CONFIG['dag']['catchup'],
    tags=AIRFLOW_CONFIG['dag']['tags'],
    max_active_runs=AIRFLOW_CONFIG['dag']['max_active_runs'],
)


def check_data(**context):
    """
    VÃ©rifie la qualitÃ© et la disponibilitÃ© des donnÃ©es brutes.
    
    Cette fonction valide les donnÃ©es d'entrÃ©e en effectuant :
    - VÃ©rification de l'existence des fichiers source
    - ContrÃ´le de l'intÃ©gritÃ© des donnÃ©es (schÃ©ma, types)
    - DÃ©tection des valeurs manquantes ou aberrantes
    - Validation des contraintes mÃ©tier
    
    Args:
        **context: Contexte Airflow avec informations sur la tÃ¢che
        
    Returns:
        dict: Rapport de validation avec mÃ©triques de qualitÃ©
        
    Raises:
        FileNotFoundError: Si les fichiers source sont introuvables
        ValueError: Si les donnÃ©es ne respectent pas les contraintes
        
    Examples:
        >>> check_data()
        {'status': 'success', 'rows': 284807, 'quality_score': 0.98}
    """
    import pandas as pd
    
    # Configuration du logging
    logger = setup_logging("INFO")
    logger.info("ðŸ” DÃ©marrage de la vÃ©rification des donnÃ©es...")
    
    try:
        # Charger les donnÃ©es depuis la configuration
        data_path = project_root / "data" / "raw" / DATA_CONFIG["source_file"]
        
        if not data_path.exists():
            raise FileNotFoundError(f"Fichier de donnÃ©es introuvable: {data_path}")
        
        # Charger le dataset
        logger.info(f"Chargement des donnÃ©es depuis: {data_path}")
        df = pd.read_csv(data_path)
        
        # Valider avec nos utilitaires
        validation_result = validate_dataset_quality(
            df=df,
            required_columns=DATA_CONFIG["validation"]["required_columns"],
            min_rows=DATA_CONFIG["validation"]["min_rows"],
            max_missing_pct=DATA_CONFIG["validation"]["max_missing_percentage"]
        )
        
        # Calculer les mÃ©triques de dÃ©sÃ©quilibre
        class_metrics = calculate_class_balance_metrics(df[DATA_CONFIG["target_column"]])
        
        # VÃ©rifications supplÃ©mentaires spÃ©cifiques au mÃ©tier
        business_checks = {
            "time_range_valid": (
                df["Time"].min() >= DATA_CONFIG["validation"]["time_range"]["min"] and
                df["Time"].max() <= DATA_CONFIG["validation"]["time_range"]["max"]
            ),
            "amount_range_valid": (
                df["Amount"].min() >= DATA_CONFIG["validation"]["amount_range"]["min"] and
                df["Amount"].max() <= DATA_CONFIG["validation"]["amount_range"]["max"]
            ),
            "class_values_valid": set(df[DATA_CONFIG["target_column"]].unique()) <= set(DATA_CONFIG["validation"]["class_values"])
        }
        
        # Compiler le rapport final
        report = {
            "status": "success" if validation_result["is_valid"] and all(business_checks.values()) else "failed",
            "message": str(validation_result["message"]),
            "data_quality": {
                "rows_count": int(validation_result["rows_count"]),
                "columns_count": int(validation_result["columns_count"]),
                "missing_percentage": float(validation_result["missing_percentage"]),
                "fraud_percentage": float(class_metrics["class_percentages"][1]),
                "imbalance_ratio": float(class_metrics["imbalance_ratio"])
            },
            "business_validation": {
                "time_range_valid": bool(business_checks["time_range_valid"]),
                "amount_range_valid": bool(business_checks["amount_range_valid"]),
                "class_values_valid": bool(business_checks["class_values_valid"])
            },
            "class_distribution": {int(k): int(v) for k, v in class_metrics["class_counts"].items()}
        }
        
        logger.info(f"âœ… Validation terminÃ©e: {report['data_quality']['rows_count']} lignes, "
                   f"{report['data_quality']['fraud_percentage']:.3f}% fraudes")
        
        return report
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors de la validation: {str(e)}")
        return {
            "status": "failed",
            "message": f"Erreur de validation: {str(e)}",
            "error": str(e)
        }


def preprocess_data(**context):
    """
    Nettoie et prÃ©traite les donnÃ©es pour l'entraÃ®nement des modÃ¨les.
    
    Effectue les transformations suivantes :
    - Suppression des doublons et valeurs manquantes
    - Traitement des outliers (Ã©crÃªtage, transformation)
    - Feature engineering (variables temporelles, agrÃ©gations)
    - Normalisation et standardisation des variables
    - SÃ©paration train/validation/test stratifiÃ©e
    
    Args:
        **context: Contexte Airflow avec informations sur la tÃ¢che
        
    Returns:
        dict: MÃ©tadonnÃ©es sur le preprocessing effectuÃ©
        
    Raises:
        ValueError: Si les donnÃ©es d'entrÃ©e sont invalides
        RuntimeError: Si le preprocessing Ã©choue
        
    Examples:
        >>> preprocess_data()
        {'rows_processed': 283726, 'features_created': 8, 'scalers_applied': 3}
    """
    print("ðŸ§¹ DÃ©marrage du preprocessing des donnÃ©es...")
    print("âœ… Preprocessing terminÃ© avec succÃ¨s")
    
    # TODO: IntÃ©grer le code du notebook partie-2.1.ipynb
    # - Charger les donnÃ©es depuis check_data
    # - Appliquer le nettoyage et feature engineering
    # - Sauvegarder les donnÃ©es traitÃ©es dans data/processed/
    # - Sauvegarder les scalers et mÃ©tadonnÃ©es
    
    return {"status": "success", "message": "DonnÃ©es prÃ©traitÃ©es"}


def generate_sdv(**context):
    """
    GÃ©nÃ¨re des donnÃ©es synthÃ©tiques frauduleuses avec SDV Gaussian Copula.
    
    Utilise la bibliothÃ¨que SDV (Synthetic Data Vault) pour crÃ©er
    des transactions frauduleuses synthÃ©tiques rÃ©alistes basÃ©es sur
    les patterns des vraies fraudes historiques.
    
    Args:
        **context: Contexte Airflow avec informations sur la tÃ¢che
        
    Returns:
        dict: Informations sur la gÃ©nÃ©ration (nombre d'Ã©chantillons, qualitÃ©)
        
    Raises:
        ImportError: Si SDV n'est pas installÃ©
        RuntimeError: Si la gÃ©nÃ©ration Ã©choue
        ValueError: Si les donnÃ©es d'entrÃ©e sont insuffisantes
        
    Examples:
        >>> generate_sdv()
        {'samples_generated': 2000, 'quality_score': 0.92, 'method': 'GaussianCopula'}
    """
    print("ðŸ¤– DÃ©marrage de la gÃ©nÃ©ration SDV...")
    print("âœ… GÃ©nÃ©ration SDV terminÃ©e avec succÃ¨s")
    
    # TODO: IntÃ©grer le code SDV du notebook partie-2.2.ipynb
    # - Charger les donnÃ©es frauduleuses depuis preprocess_data
    # - EntraÃ®ner le modÃ¨le GaussianCopulaSynthesizer
    # - GÃ©nÃ©rer les Ã©chantillons synthÃ©tiques
    # - Ã‰valuer la qualitÃ© des donnÃ©es gÃ©nÃ©rÃ©es
    # - Sauvegarder dans data/synthetic/
    
    return {"status": "success", "samples": 2000, "method": "SDV"}


def generate_smote(**context):
    """
    GÃ©nÃ¨re des donnÃ©es synthÃ©tiques avec les techniques SMOTE.
    
    Applique diffÃ©rentes variantes de SMOTE (Synthetic Minority Oversampling
    Technique) pour augmenter le nombre d'Ã©chantillons frauduleux :
    - SMOTE classique
    - BorderlineSMOTE (focus sur les cas limites)
    - Fallback vers surÃ©chantillonnage simple si SMOTE indisponible
    
    Args:
        **context: Contexte Airflow avec informations sur la tÃ¢che
        
    Returns:
        dict: RÃ©sultats de gÃ©nÃ©ration pour chaque mÃ©thode testÃ©e
        
    Raises:
        ImportError: Si imbalanced-learn n'est pas installÃ©
        ValueError: Si les paramÃ¨tres de sampling sont invalides
        RuntimeError: Si toutes les mÃ©thodes Ã©chouent
        
    Examples:
        >>> generate_smote()
        {'SMOTE': 5000, 'BorderlineSMOTE': 4800, 'best_method': 'SMOTE'}
    """
    print("âš–ï¸ DÃ©marrage de la gÃ©nÃ©ration SMOTE...")
    print("âœ… GÃ©nÃ©ration SMOTE terminÃ©e avec succÃ¨s")
    
    # TODO: IntÃ©grer le code SMOTE du notebook partie-2.2.ipynb
    # - Tester SMOTE, BorderlineSMOTE et mÃ©thode simple
    # - Comparer les rÃ©sultats et sÃ©lectionner la meilleure
    # - Sauvegarder tous les datasets gÃ©nÃ©rÃ©s
    # - Retourner les mÃ©triques de comparaison
    
    return {"status": "success", "methods_tested": 3}


def select_best(**context):
    """
    SÃ©lectionne le meilleur dataset synthÃ©tique basÃ© sur les mÃ©triques de qualitÃ©.
    
    Compare les diffÃ©rents datasets gÃ©nÃ©rÃ©s (SDV, SMOTE, BorderlineSMOTE)
    selon plusieurs critÃ¨res :
    - QualitÃ© des donnÃ©es synthÃ©tiques (rÃ©alisme, diversitÃ©)
    - AmÃ©lioration du dÃ©sÃ©quilibre des classes
    - Performance sur des modÃ¨les de validation
    - MÃ©triques de distance statistique
    
    Args:
        **context: Contexte Airflow avec informations sur la tÃ¢che
        
    Returns:
        dict: Informations sur le dataset sÃ©lectionnÃ© et les mÃ©triques
        
    Raises:
        ValueError: Si aucun dataset valide n'est disponible
        RuntimeError: Si l'Ã©valuation Ã©choue
        
    Examples:
        >>> select_best()
        {'best_method': 'SMOTE', 'quality_score': 0.95, 'dataset_size': 50000}
    """
    print("ðŸ† DÃ©marrage de la sÃ©lection du meilleur dataset...")
    print("âœ… SÃ©lection terminÃ©e avec succÃ¨s")
    
    # TODO: ImplÃ©menter la logique de sÃ©lection
    # - Charger tous les datasets gÃ©nÃ©rÃ©s
    # - Calculer les mÃ©triques de qualitÃ©
    # - Comparer les performances
    # - SÃ©lectionner et sauvegarder le meilleur
    # - CrÃ©er un rapport de comparaison
    
    return {"status": "success", "best_method": "auto-selected"}


def notify(**context):
    """
    Envoie les notifications de fin de pipeline aux Ã©quipes concernÃ©es.
    
    GÃ©nÃ¨re et envoie un rapport d'exÃ©cution comprenant :
    - Statut global du pipeline (succÃ¨s/Ã©chec)
    - MÃ©triques de performance de chaque Ã©tape
    - Datasets gÃ©nÃ©rÃ©s et leur qualitÃ©
    - Recommandations pour les prochaines Ã©tapes
    - Alertes si des seuils critiques sont dÃ©passÃ©s
    
    Args:
        **context: Contexte Airflow avec informations sur toutes les tÃ¢ches
        
    Returns:
        dict: Confirmation d'envoi des notifications
        
    Raises:
        ConnectionError: Si l'envoi des notifications Ã©choue
        ValueError: Si les donnÃ©es du rapport sont incomplÃ¨tes
        
    Examples:
        >>> notify()
        {'notifications_sent': 3, 'recipients': ['team@fluzz.com'], 'status': 'sent'}
    """
    from datetime import datetime
    
    # Configuration du logging
    logger = setup_logging("INFO")
    logger.info("ðŸ“§ PrÃ©paration des notifications...")
    
    try:
        # RÃ©cupÃ©rer les rÃ©sultats des tÃ¢ches prÃ©cÃ©dentes via XCom
        task_instance = context['task_instance']
        dag_run = context['dag_run']
        
        # Collecter les rÃ©sultats de toutes les tÃ¢ches
        pipeline_results = {
            'execution_date': dag_run.execution_date.isoformat(),
            'dag_run_id': dag_run.run_id,
            'dag_id': dag_run.dag_id
        }
        
        # Essayer de rÃ©cupÃ©rer les rÃ©sultats des tÃ¢ches prÃ©cÃ©dentes
        try:
            pipeline_results['data_validation'] = task_instance.xcom_pull(task_ids='check_data')
            pipeline_results['preprocessing'] = task_instance.xcom_pull(task_ids='preprocess_data')
            pipeline_results['sdv_generation'] = task_instance.xcom_pull(task_ids='synthetic_generation.generate_sdv')
            pipeline_results['smote_generation'] = task_instance.xcom_pull(task_ids='synthetic_generation.generate_smote')
            pipeline_results['best_selection'] = task_instance.xcom_pull(task_ids='select_best')
        except Exception as e:
            logger.warning(f"Impossible de rÃ©cupÃ©rer certains rÃ©sultats XCom: {e}")
            pipeline_results['warning'] = "Certains rÃ©sultats de tÃ¢ches ne sont pas disponibles"
        
        # GÃ©nÃ©rer le rapport avec nos utilitaires
        report_path = project_root / "reports" / f"pipeline_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        report_content = generate_pipeline_report(
            pipeline_results=pipeline_results,
            output_file=str(report_path)
        )
        
        # PrÃ©parer les informations de notification
        notification_config = AIRFLOW_CONFIG.get('notifications', {})
        recipients = notification_config.get('success', {}).get('recipients', ['data-science@fluzz.com'])
        
        # DÃ©terminer le statut global
        has_failures = any(
            result and result.get('status') == 'failed' 
            for result in pipeline_results.values() 
            if isinstance(result, dict)
        )
        
        global_status = "failed" if has_failures else "success"
        
        logger.info(f"âœ… Rapport gÃ©nÃ©rÃ©: {report_path}")
        logger.info(f"ðŸ“Š Statut global: {global_status}")
        logger.info(f"ðŸ“§ Destinataires configurÃ©s: {recipients}")
        
        return {
            "status": "success",
            "notifications_sent": True,
            "global_pipeline_status": global_status,
            "report_path": str(report_path),
            "recipients": recipients,
            "results_summary": {
                key: value.get('status', 'unknown') if isinstance(value, dict) else 'completed'
                for key, value in pipeline_results.items()
                if key not in ['execution_date', 'dag_run_id', 'dag_id']
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors de la gÃ©nÃ©ration du rapport: {str(e)}")
        return {
            "status": "failed",
            "message": f"Erreur de notification: {str(e)}",
            "error": str(e)
        }

# Tasks
check_task = PythonOperator(
    task_id='check_data',
    python_callable=check_data,
    dag=dag,
)

preprocess_task = PythonOperator(
    task_id='preprocess_data',
    python_callable=preprocess_data,
    dag=dag,
)

with TaskGroup("synthetic_generation", dag=dag) as synthetic_group:
    sdv_task = PythonOperator(
        task_id='generate_sdv',
        python_callable=generate_sdv,
    )
    
    smote_task = PythonOperator(
        task_id='generate_smote',
        python_callable=generate_smote,
    )

select_task = PythonOperator(
    task_id='select_best',
    python_callable=select_best,
    dag=dag,
)

notify_task = PythonOperator(
    task_id='notify',
    python_callable=notify,
    dag=dag,
)

check_task >> preprocess_task >> synthetic_group >> select_task >> notify_task